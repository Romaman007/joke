{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "outputs": [],
   "source": [
    "# def pixel_norm(x):\n",
    "#     eps= 10e-8\n",
    "#     return x/torch.sqrt(torch.mean(x,dim=1)+eps)\n",
    "\n",
    "class Pixel_norm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.eps=10e-8\n",
    "\n",
    "    def forward(self,x):\n",
    "            return x/torch.sqrt(torch.mean(x,dim=1,keepdim=True)+self.eps)\n",
    "\n",
    "\n",
    "class WConv(nn.Module):\n",
    "    def __init__(self,in_chan,out_chan,kernel=3,stride=1,padding=1):\n",
    "        super().__init__()\n",
    "        self.conv=nn.Conv2d(in_chan,out_chan,kernel,stride,padding)\n",
    "        self.equalized_weights =(2/(in_chan*kernel**2))**0.5\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.conv(x*self.equalized_weights)\n",
    "\n",
    "\n",
    "class WConvTrans(nn.Module):\n",
    "    def __init__(self,in_chan,out_chan,kernel=3,stride=1,padding=1):\n",
    "        super().__init__()\n",
    "        self.conv=nn.ConvTranspose2d(in_chan,out_chan,kernel,stride,padding)\n",
    "        self.equalized_weights =(2/(out_chan*kernel**2))**0.5\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.conv(x*self.equalized_weights)\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self,in_chan,out_chan):\n",
    "        super().__init__()\n",
    "        self.conv = WConv(in_chan,out_chan)\n",
    "        self.conv1 = WConv(out_chan,out_chan)\n",
    "        self.pix = Pixel_norm()\n",
    "        self.leaky = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.pix(self.leaky(self.conv1(self.pix(self.leaky(self.conv(x))))))\n",
    "\n",
    "class DisBlock(nn.Module):\n",
    "    def __init__(self,in_chan,out_chan):\n",
    "        super().__init__()\n",
    "        self.conv = WConv(in_chan,in_chan)\n",
    "        self.conv1 = WConv(in_chan,out_chan)\n",
    "        self.leaky = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.leaky(self.conv1(self.leaky(self.conv(x))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,in_dim,img_channel):\n",
    "        super(Generator,self).__init__()\n",
    "        self.blocks =nn.ModuleList()\n",
    "        self.rgb_layers = nn.ModuleList()\n",
    "        self.rgb_layers.append(WConv(in_dim,img_channel,1,1,0))\n",
    "        self.up = nn.Upsample(scale_factor=2,mode='nearest')\n",
    "        self.blocks.append(nn.Sequential(\n",
    "            WConvTrans(in_dim,in_dim,4,1,0),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            Pixel_norm(),\n",
    "            WConv(in_dim,in_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            Pixel_norm(),\n",
    "        ))\n",
    "\n",
    "        for i in range(3):\n",
    "            self.blocks.append(\n",
    "                ConvBlock(in_dim,in_dim)\n",
    "            )\n",
    "            self.rgb_layers.append(WConv(in_dim,img_channel,1,1,0))\n",
    "        n=0\n",
    "        while in_dim//2**n>16:\n",
    "\n",
    "            self.blocks.append(\n",
    "                ConvBlock(in_dim//2**n,in_dim//2**(n+1))\n",
    "            )\n",
    "            self.rgb_layers.append(WConv(in_dim//2**(n),img_channel,1,1,0))\n",
    "\n",
    "            n+=1\n",
    "        self.rgb_layers.append(WConv(in_dim//2**(n),img_channel,1,1,0))\n",
    "\n",
    "    def forward(self,x, out_size,alpha):\n",
    "        i=0\n",
    "        while 2**i<out_size:\n",
    "            i+=1\n",
    "        x=self.blocks[0](x)\n",
    "        x_up=x\n",
    "        for j in range(1,i-1):\n",
    "            print(j)\n",
    "            x_up=self.up(x)\n",
    "            x=self.blocks[j](x_up)\n",
    "        x_rgb = self.rgb_layers[i-2](x_up)\n",
    "        print(x_rgb.shape)\n",
    "        x_rgb_up = self.rgb_layers[i-1](x)\n",
    "        print(x_rgb_up.shape)\n",
    "        return torch.tanh((1-alpha)*x_rgb+alpha*x_rgb_up)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,in_chan,img_channel):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.pool = nn.AvgPool2d(2,2)\n",
    "        self.blocks =nn.ModuleList()\n",
    "        self.rgb_layers = nn.ModuleList()\n",
    "        # self.rgb_layers.append(WConv(img_channel,img_channel,1,1,0))\n",
    "        n=16\n",
    "        while n<in_chan:\n",
    "            self.blocks.append(DisBlock(n,n*2))\n",
    "            self.rgb_layers.append(WConv(img_channel,n,1,1,0))\n",
    "            n=n*2\n",
    "\n",
    "        for i in range(3):\n",
    "            self.blocks.append(DisBlock(in_chan,in_chan))\n",
    "            self.rgb_layers.append(WConv(img_channel,in_chan,1,1,0))\n",
    "        self.blocks.append(nn.Sequential(\n",
    "            WConv(in_chan+1,in_chan),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            WConv(in_chan,in_chan,4,1,0),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            WConv(in_chan,1,1,1,0),\n",
    "            nn.Sigmoid()\n",
    "        ))\n",
    "        self.rgb_layers.append(WConv(img_channel,in_chan,1,1,0))\n",
    "    def minibatch_std(self, x):\n",
    "        batch_statistics = (\n",
    "            torch.std(x, dim=0).mean().repeat(x.shape[0], 1, x.shape[2], x.shape[3])\n",
    "        )\n",
    "        return torch.cat([x, batch_statistics], dim=1)\n",
    "\n",
    "    def forward(self,x,size,alpha=0.5):\n",
    "        i=0\n",
    "        while 2**i<size:\n",
    "            i+=1\n",
    "        x_rgb=self.rgb_layers[-(i-1)](x)\n",
    "        if i==2:\n",
    "            x=self.minibatch_std(x_rgb)\n",
    "            return (self.blocks[-1](x)).view(x.shape[0], -1)\n",
    "\n",
    "        x_down= self.pool(self.blocks[-(i-1)](x_rgb))\n",
    "        x=self.rgb_layers[-(i-2)](self.pool(x))\n",
    "        x=(1-alpha)*x_down+alpha*x\n",
    "\n",
    "        for j in range(i-2,1,-1):\n",
    "            x=self.blocks[-j](x)\n",
    "            x=self.pool(x)\n",
    "        x=self.minibatch_std(x)\n",
    "        return (self.blocks[-1](x)).view(x.shape[0], -1)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 4])\n",
      "torch.Size([2, 3, 4, 4])\n",
      "torch.Size([2, 3, 4, 4])\n",
      "tensor([[0.4948],\n",
      "        [0.4948]], grad_fn=<ViewBackward0>)\n",
      "1\n",
      "torch.Size([2, 3, 8, 8])\n",
      "torch.Size([2, 3, 8, 8])\n",
      "torch.Size([2, 3, 8, 8])\n",
      "tensor([[0.4948],\n",
      "        [0.4948]], grad_fn=<ViewBackward0>)\n",
      "1\n",
      "2\n",
      "torch.Size([2, 3, 16, 16])\n",
      "torch.Size([2, 3, 16, 16])\n",
      "torch.Size([2, 3, 16, 16])\n",
      "tensor([[0.4948],\n",
      "        [0.4948]], grad_fn=<ViewBackward0>)\n",
      "1\n",
      "2\n",
      "3\n",
      "torch.Size([2, 3, 32, 32])\n",
      "torch.Size([2, 3, 32, 32])\n",
      "torch.Size([2, 3, 32, 32])\n",
      "tensor([[0.4948],\n",
      "        [0.4948]], grad_fn=<ViewBackward0>)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "torch.Size([2, 3, 64, 64])\n",
      "torch.Size([2, 3, 64, 64])\n",
      "torch.Size([2, 3, 64, 64])\n",
      "tensor([[0.4948],\n",
      "        [0.4948]], grad_fn=<ViewBackward0>)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "torch.Size([2, 3, 128, 128])\n",
      "torch.Size([2, 3, 128, 128])\n",
      "torch.Size([2, 3, 128, 128])\n",
      "tensor([[0.4948],\n",
      "        [0.4948]], grad_fn=<ViewBackward0>)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 3, 256, 256])\n",
      "torch.Size([2, 3, 256, 256])\n",
      "tensor([[0.4948],\n",
      "        [0.4948]], grad_fn=<ViewBackward0>)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "torch.Size([2, 3, 512, 512])\n",
      "torch.Size([2, 3, 512, 512])\n",
      "torch.Size([2, 3, 512, 512])\n",
      "tensor([[0.4948],\n",
      "        [0.4948]], grad_fn=<ViewBackward0>)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "torch.Size([2, 3, 1024, 1024])\n",
      "torch.Size([2, 3, 1024, 1024])\n",
      "torch.Size([2, 3, 1024, 1024])\n",
      "tensor([[0.4948],\n",
      "        [0.4948]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "gen = Generator(512,3)\n",
    "x= torch.randn((2,512,1,1))\n",
    "gen.train()\n",
    "dis = Discriminator(512,3)\n",
    "dis.train()\n",
    "\n",
    "for i in range(2,11):\n",
    "    im=gen(x,2**i,0.5)\n",
    "    print(im.shape)\n",
    "    print(dis(im,2**i))\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "for j in range(4-2,1,-1):\n",
    "    print(j)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}