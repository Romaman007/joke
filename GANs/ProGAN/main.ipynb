{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# def pixel_norm(x):\n",
    "#     eps= 10e-8\n",
    "#     return x/torch.sqrt(torch.mean(x,dim=1)+eps)\n",
    "\n",
    "class Pixel_norm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.eps=10e-8\n",
    "\n",
    "    def forward(self,x):\n",
    "            return x/torch.sqrt(torch.mean(x**2,dim=1,keepdim=True)+self.eps)\n",
    "\n",
    "\n",
    "class WConv(nn.Module):\n",
    "    def __init__(self,in_chan,out_chan,kernel=3,stride=1,padding=1):\n",
    "        super().__init__()\n",
    "        self.conv=nn.Conv2d(in_chan,out_chan,kernel,stride,padding,)\n",
    "        self.equalized_weights =(2/(in_chan*kernel**2))**0.5\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.conv(x*self.equalized_weights)\n",
    "\n",
    "\n",
    "class WConvTrans(nn.Module):\n",
    "    def __init__(self,in_chan,out_chan,kernel=3,stride=1,padding=1):\n",
    "        super().__init__()\n",
    "        self.conv=nn.ConvTranspose2d(in_chan,out_chan,kernel,stride,padding)\n",
    "        self.equalized_weights =(2/(out_chan*kernel**2))**0.5\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.conv(x*self.equalized_weights)\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self,in_chan,out_chan):\n",
    "        super().__init__()\n",
    "        self.conv = WConv(in_chan,out_chan)\n",
    "        self.conv1 = WConv(out_chan,out_chan)\n",
    "        self.pix = Pixel_norm()\n",
    "        self.leaky = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.pix(self.leaky(self.conv1(self.pix(self.leaky(self.conv(x))))))\n",
    "\n",
    "class DisBlock(nn.Module):\n",
    "    def __init__(self,in_chan,out_chan):\n",
    "        super().__init__()\n",
    "        self.conv = WConv(in_chan,in_chan)\n",
    "        self.conv1 = WConv(in_chan,out_chan)\n",
    "        self.leaky = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.leaky(self.conv1(self.leaky(self.conv(x))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,in_dim,img_channel):\n",
    "        super(Generator,self).__init__()\n",
    "        self.blocks =nn.ModuleList()\n",
    "        self.rgb_layers = nn.ModuleList()\n",
    "        self.rgb_layers.append(WConv(in_dim,img_channel,1,1,0))\n",
    "        self.up = nn.Upsample(scale_factor=2,mode='nearest')\n",
    "        self.blocks.append(nn.Sequential(\n",
    "            WConvTrans(in_dim,in_dim,4,1,0),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            Pixel_norm(),\n",
    "            WConv(in_dim,in_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            Pixel_norm(),\n",
    "        ))\n",
    "\n",
    "        for i in range(3):\n",
    "            self.blocks.append(ConvBlock(in_dim,in_dim))\n",
    "            self.rgb_layers.append(WConv(in_dim,img_channel,1,1,0))\n",
    "\n",
    "        n=0\n",
    "        while in_dim//2**n>16:\n",
    "            self.blocks.append(ConvBlock(in_dim//2**n,in_dim//2**(n+1)))\n",
    "            self.rgb_layers.append(WConv(in_dim//2**(n),img_channel,1,1,0))\n",
    "            n+=1\n",
    "        self.rgb_layers.append(WConv(in_dim//2**(n),img_channel,1,1,0))\n",
    "\n",
    "    def forward(self,x, out_size,alpha):\n",
    "        i=0\n",
    "        while 2**i<out_size:\n",
    "            i+=1\n",
    "        x=self.blocks[0](x)\n",
    "        x_up=x\n",
    "        for j in range(1,i-1):\n",
    "            x_up=self.up(x)\n",
    "            x=self.blocks[j](x_up)\n",
    "        x_rgb = self.rgb_layers[i-2](x_up)\n",
    "        x_rgb_up = self.rgb_layers[i-1](x)\n",
    "        return torch.tanh((1-alpha)*x_rgb+alpha*x_rgb_up)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,in_chan,img_channel):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.pool = nn.AvgPool2d(2,2)\n",
    "        self.blocks =nn.ModuleList()\n",
    "        self.rgb_layers = nn.ModuleList()\n",
    "        # self.rgb_layers.append(WConv(img_channel,img_channel,1,1,0))\n",
    "        n=16\n",
    "        while n<in_chan:\n",
    "            self.blocks.append(DisBlock(n,n*2))\n",
    "            self.rgb_layers.append(WConv(img_channel,n,1,1,0))\n",
    "            n=n*2\n",
    "\n",
    "        for i in range(3):\n",
    "            self.blocks.append(DisBlock(in_chan,in_chan))\n",
    "            self.rgb_layers.append(WConv(img_channel,in_chan,1,1,0))\n",
    "        self.blocks.append(nn.Sequential(\n",
    "            WConv(in_chan+1,in_chan),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            WConv(in_chan,in_chan,4,1,0),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            WConv(in_chan,1,1,1,0),\n",
    "            nn.Sigmoid()\n",
    "        ))\n",
    "        self.rgb_layers.append(WConv(img_channel,in_chan,1,1,0))\n",
    "    def minibatch_std(self, x):\n",
    "        batch_statistics = (\n",
    "            torch.std(x, dim=0).mean().repeat(x.shape[0], 1, x.shape[2], x.shape[3])\n",
    "        )\n",
    "        return torch.cat([x, batch_statistics], dim=1)\n",
    "\n",
    "    def forward(self,x,size,alpha=0.5):\n",
    "        i=0\n",
    "        while 2**i<size:\n",
    "            i+=1\n",
    "        x_rgb=self.rgb_layers[-(i-1)](x)\n",
    "        if i==2:\n",
    "            x=self.minibatch_std(x_rgb)\n",
    "            return (self.blocks[-1](x)).view(x.shape[0], -1)\n",
    "\n",
    "        x_down= self.pool(self.blocks[-(i-1)](x_rgb))\n",
    "        x=self.rgb_layers[-(i-2)](self.pool(x))\n",
    "        x=(1-alpha)*x_down+alpha*x\n",
    "\n",
    "        for j in range(i-2,1,-1):\n",
    "            x=self.blocks[-j](x)\n",
    "            x=self.pool(x)\n",
    "        x=self.minibatch_std(x)\n",
    "        return (self.blocks[-1](x)).view(x.shape[0], -1)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# gen = Generator(512,3)\n",
    "# x= torch.randn((32,3,4,4))\n",
    "# dis = Discriminator(512,3)\n",
    "# dis(x,4,1e-5)\n",
    "# for i in range(2,11):\n",
    "#     im=gen(x,2**i,0.5)\n",
    "#     print(im.shape)\n",
    "#     print(dis(im,2**i))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATASET = 'dataset/'\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZES = [128, 128, 64, 32, 16, 16, 8, 8, 4]\n",
    "IMG_START_SIZE = 4\n",
    "CHANNELS_IMG = 3\n",
    "IN_CHANNELS = 512\n",
    "DISC_ITERATIONS = 1\n",
    "LAMBDA_GP = 10\n",
    "epochs = [10] * len(BATCH_SIZES)\n",
    "FIXED_NOISE = torch.randn(16, IN_CHANNELS, 1, 1).to(DEVICE)\n",
    "NUM_WORKERS = 4\n",
    "CHECKPOINT_GEN = \"gen.pth\"\n",
    "CHECKPOINT_DISC = \"disc.pth\"\n",
    "SAVE_MODEL = True\n",
    "LOAD_MODEL = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "def plot_to_tensorboard(\n",
    "    writer, loss_disc, loss_gen, real, fake, tensorboard_step\n",
    "):\n",
    "    writer.add_scalar(\"Loss Critic\", loss_disc, global_step=tensorboard_step)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        img_grid_real = torchvision.utils.make_grid(real[:16], normalize=True)\n",
    "        img_grid_fake = torchvision.utils.make_grid(fake[:16], normalize=True)\n",
    "        writer.add_image(\"Real\", img_grid_real, global_step=tensorboard_step)\n",
    "        writer.add_image(\"Fake\", img_grid_fake, global_step=tensorboard_step)\n",
    "\n",
    "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=\"cuda\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from math import log2\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.backends.cudnn.benchmarks = True\n",
    "\n",
    "def gradient_penalty(disc, real, fake, alpha, size, device=DEVICE):\n",
    "    BATCH_SIZE, C, H, W = real.shape\n",
    "    beta = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
    "    interpolated_images = real * beta + fake.detach() * (1 - beta)\n",
    "    interpolated_images.requires_grad_(True)\n",
    "    mixed_scores = disc(interpolated_images, size, alpha)\n",
    "\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty\n",
    "\n",
    "def get_loader(image_size):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    )\n",
    "    batch_size = BATCH_SIZES[int(log2(image_size / 4))]\n",
    "    dataset = datasets.ImageFolder(\n",
    "        root=DATASET, transform=transform,\n",
    "    )\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return loader, dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current image size: 4\n",
      "Epoch [1/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/235 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [27]\u001B[0m, in \u001B[0;36m<cell line: 108>\u001B[1;34m()\u001B[0m\n\u001B[0;32m    105\u001B[0m         size\u001B[38;5;241m=\u001B[39msize\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 109\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [27]\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 88\u001B[0m     tensorboard_step, alpha \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_fn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     89\u001B[0m \u001B[43m        \u001B[49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     90\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdisc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     91\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     92\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     93\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[43m        \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     95\u001B[0m \u001B[43m        \u001B[49m\u001B[43mopt_critic\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     96\u001B[0m \u001B[43m        \u001B[49m\u001B[43mopt_gen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     97\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtensorboard_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     98\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwriter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     99\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    101\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m SAVE_MODEL:\n\u001B[0;32m    102\u001B[0m         save_checkpoint(gen, opt_gen, filename\u001B[38;5;241m=\u001B[39mCHECKPOINT_GEN)\n",
      "Input \u001B[1;32mIn [27]\u001B[0m, in \u001B[0;36mtrain_fn\u001B[1;34m(size, disc, gen, loader, dataset, alpha, opt_disc, opt_gen, tensorboard_step, writer)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_fn\u001B[39m(size,disc,gen,loader,dataset,alpha,opt_disc,opt_gen,tensorboard_step,writer):\n\u001B[0;32m      2\u001B[0m     loop \u001B[38;5;241m=\u001B[39m tqdm(loader, leave\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m----> 3\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch_idx, (real, _) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(loop):\n\u001B[0;32m      4\u001B[0m         real \u001B[38;5;241m=\u001B[39m real\u001B[38;5;241m.\u001B[39mto(DEVICE)\n\u001B[0;32m      5\u001B[0m         cur_batch_size \u001B[38;5;241m=\u001B[39m real\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32mC:\\anaconda3\\envs\\main\\lib\\site-packages\\tqdm\\std.py:1195\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1192\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1194\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1195\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1196\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1197\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1198\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32mC:\\anaconda3\\envs\\main\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:435\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    433\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[0;32m    434\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 435\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\anaconda3\\envs\\main\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:381\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    379\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    380\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[1;32m--> 381\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\anaconda3\\envs\\main\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1034\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m   1027\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1028\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[0;32m   1029\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[0;32m   1030\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[0;32m   1031\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[0;32m   1032\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[0;32m   1033\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[1;32m-> 1034\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1035\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[0;32m   1036\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[1;32mC:\\anaconda3\\envs\\main\\lib\\multiprocessing\\process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[0;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    120\u001B[0m _cleanup()\n\u001B[1;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[1;32mC:\\anaconda3\\envs\\main\\lib\\multiprocessing\\context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\anaconda3\\envs\\main\\lib\\multiprocessing\\context.py:327\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    324\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m    326\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_win32\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[1;32m--> 327\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\anaconda3\\envs\\main\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     92\u001B[0m     reduction\u001B[38;5;241m.\u001B[39mdump(prep_data, to_child)\n\u001B[1;32m---> 93\u001B[0m     \u001B[43mreduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_child\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     95\u001B[0m     set_spawning_popen(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[1;32mC:\\anaconda3\\envs\\main\\lib\\multiprocessing\\reduction.py:60\u001B[0m, in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdump\u001B[39m(obj, file, protocol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     59\u001B[0m     \u001B[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m     \u001B[43mForkingPickler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def train_fn(size,disc,gen,loader,dataset,alpha,opt_disc,opt_gen,tensorboard_step,writer):\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch_idx, (real, _) in enumerate(loop):\n",
    "        real = real.to(DEVICE)\n",
    "        cur_batch_size = real.shape[0]\n",
    "        noise = torch.randn(cur_batch_size, IN_CHANNELS, 1, 1).to(DEVICE)\n",
    "        fake = gen(noise, size, alpha)\n",
    "\n",
    "        #Discriminator loss\n",
    "        critic_real = disc(real, size, alpha)\n",
    "        critic_fake = disc(fake.detach(),  size, alpha)\n",
    "        gp = gradient_penalty(disc, real, fake, alpha, size, device=DEVICE)\n",
    "\n",
    "        loss_disc = (\n",
    "            -(torch.mean(critic_real) - torch.mean(critic_fake))\n",
    "            + LAMBDA_GP * gp\n",
    "            + (0.001 * torch.mean(critic_real ** 2))\n",
    "        )\n",
    "        opt_disc.zero_grad()\n",
    "        loss_disc.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        # Generator loss\n",
    "        gen_fake = disc(fake,size, alpha)\n",
    "        loss_gen = -torch.mean(gen_fake)\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        alpha += cur_batch_size / (\n",
    "            (epochs[size//4] * 0.5) * len(dataset)\n",
    "        )\n",
    "        alpha = min(alpha, 1)\n",
    "\n",
    "        if batch_idx % 500 == 0:\n",
    "            with torch.no_grad():\n",
    "                fixed_fakes = gen(FIXED_NOISE,size,alpha) * 0.5 + 0.5\n",
    "            plot_to_tensorboard(\n",
    "                writer,\n",
    "                loss_disc.item(),\n",
    "                loss_gen.item(),\n",
    "                real.detach(),\n",
    "                fixed_fakes.detach(),\n",
    "                tensorboard_step,\n",
    "            )\n",
    "            tensorboard_step += 1\n",
    "\n",
    "        loop.set_postfix(\n",
    "            gp=gp.item(),\n",
    "            loss_critic=loss_disc.item(),\n",
    "        )\n",
    "\n",
    "    return tensorboard_step, alpha\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    gen = Generator( IN_CHANNELS, CHANNELS_IMG ).to(DEVICE)\n",
    "    disc = Discriminator( IN_CHANNELS, CHANNELS_IMG).to(DEVICE)\n",
    "    opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.99))\n",
    "    opt_critic = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.99))\n",
    "\n",
    "    if LOAD_MODEL:\n",
    "        load_checkpoint(\n",
    "            CHECKPOINT_GEN, gen, opt_gen, LEARNING_RATE,\n",
    "        )\n",
    "        load_checkpoint(\n",
    "            CHECKPOINT_DISC, disc, opt_critic, LEARNING_RATE,\n",
    "        )\n",
    "\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "    writer = SummaryWriter(f\"logs/gan\")\n",
    "    tensorboard_step = 0\n",
    "    size = IMG_START_SIZE\n",
    "    \n",
    "\n",
    "    for num_epochs in epochs[size//4:]:\n",
    "        alpha = 1e-5\n",
    "        loader, dataset = get_loader(size)\n",
    "        print(f\"Current image size: {size}\")\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "            tensorboard_step, alpha = train_fn(\n",
    "                size,\n",
    "                disc,\n",
    "                gen,\n",
    "                loader,\n",
    "                dataset,\n",
    "                alpha,\n",
    "                opt_critic,\n",
    "                opt_gen,\n",
    "                tensorboard_step,\n",
    "                writer,\n",
    "            )\n",
    "\n",
    "            if SAVE_MODEL:\n",
    "                save_checkpoint(gen, opt_gen, filename=CHECKPOINT_GEN)\n",
    "                save_checkpoint(disc, opt_critic, filename=CHECKPOINT_DISC)\n",
    "\n",
    "        size=size*2\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}